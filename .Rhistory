mutate(crow_dist = crow_fly_distance(
pickup_longitude,
pickup_latitude,
dropoff_longitude,
dropoff_latitude
))
nyc |>
mutate(crow_dist = crow_fly_distance(
pickup_longitude,
pickup_latitude,
dropoff_longitude,
dropoff_latitude
)) |>
filter(year == 2016, month == 1) |>
select(
contains('longitude'), contains('latitude'), crow_dist
) |>
collect()
nyc |>
filter(year == 2016, month == 1) |> collect()
.Last.value -> xx
# context must be the first argument
haversine <- function(pickup_lat, pickup_long, dropoff_lat, dropoff_long) {
# Convert degrees to radians
pickup_lat <- pickup_lat * pi / 180
pickup_long <- pickup_long * pi / 180
dropoff_lat <- dropoff_lat * pi / 180
dropoff_long <- dropoff_long * pi / 180
# Radius of the Earth in km
R <- 6371
# Differences in coordinates
dlat <- dropoff_lat - pickup_lat
dlon <- dropoff_long - pickup_long
# Haversine formula
a <- sin(dlat/2)^2 + cos(pickup_lat) * cos(dropoff_lat) * sin(dlon/2)^2
c <- 2 * asin(min(1, sqrt(a)))
distance <- R * c
distance
}
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude))
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(c)
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('latitude', c))
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('latitude'), c)
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('pickup', 'dropoff'), c)
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('pickup'), contains('dropoff'), c)
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('pickup'), contains('dropoff'), c)
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('pickup'), contains('dropoff'), c) |> arrange(-c)
xx |> mutate(c = haversine(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)) |> select(contains('pickup'), contains('dropoff'), c) |> arrange(c)
nyc
glimpse(xx)
renv::install('janitor')
register_scalar_function(
# What should we call the function?
name = "crow_fly_distance",
# Define the function
# context must be the first argument
fun = function(context, var){
janitor::make_clean_names(var, case = "snake")
},
# Schemas of input and output
in_type = schema(var = string()),
out_type = string(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
janitor::make_clean_names(var, case = "snake")
},
# Schemas of input and output
in_type = schema(var = string()),
out_type = string(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc
nyc |>
mutate(clean_rate_code = clean_factors(rate_code))
nyc |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
head() |>
collect()
nyc
nyc |>
filter(year == 2019) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
head() |>
collect()
source("~/github.com/oman-rusers-arrow/code/01-basics.R", echo=TRUE)
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
janitor::make_clean_names(var, case = "snake")
},
# Schemas of input and output
in_type = schema(var = string()),
out_type = string(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
head() |>
collect()
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
janitor::make_clean_names(var, case = "snake")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code))
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
head() |>
select(contains('rate_code')) |>
collect()
nyc
register_scalar_function(
name = "time_diff_minutes",
function(context, pickup, dropoff) {
difftime(dropoff, pickup, units = "mins") |>
round() |>
as.integer()
},
in_type = schema(
pickup = timestamp(unit = "ms"),
dropoff = timestamp(unit = "ms")
),
out_type = int32(),
auto_convert = TRUE
)
nyc |>
mutate(
duration_minutes = time_diff_minutes(pickup_datetime, dropoff_datetime)
) |>
select(pickup_datetime, dropoff_datetime, duration_minutes) |>
head() |>
collect()
janitor::make_clean_names("ioajef afoija fp")
library(janitor)
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
janitor::make_clean_names(var, case = "snake")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
head() |>
select(contains('rate_code')) |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code'))
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
var
# janitor::make_clean_names(var, case = "snake")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
stringr::str_to_lower(var)
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
register_scalar_function(
# What should we call the function?
name = "clean_factors",
# Define the function
# context must be the first argument
fun = function(context, var){
stringr::str_to_lower(var) |>
stringr::str_replace_all(" ", "_")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
nyc |>
filter(year == 2019) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
sample_n(1000) |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
to_duckdb() |>
sample_n(1000) |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
to_duckdb() |>
sample(1000) |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
to_duckdb() |>
sample_n(n = 10) |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_factors(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
nyc
register_scalar_function(
# What should we call the function?
name = "clean_me",
# Define the function
# context must be the first argument
fun = function(context, var){
stringr::str_to_lower(var) |>
stringr::str_replace_all(" ", "_")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
head() |>
collect()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
# head() |>
collect()
.Last.value |> sample_n(n=100)
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount))
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
show_query()
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
show_query()
nyc |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
show_query()
nyc
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount),
tip_pc = tip_amount, total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount, total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount, total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount, total_amount) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = difftime(dropoff_datetime , pickup_datetime)) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('datetime'), contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = difftime(dropoff_datetime , pickup_datetime)) |>
show_query()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('datetime'), contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = dropoff_datetime - pickup_datetime)) |>
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('datetime'), contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
open_dataset("data/airlines/Combined_Flights_2018.csv")
open_csv_dataset(
sources = "data/airlines/Combined_Flights_2018.csv")
open_csv_dataset(sources = "data/airlines/Combined_Flights_2018.csv") |>
count(DestState)
open_csv_dataset(sources = "data/airlines/Combined_Flights_2018.csv") |>
count(DestState) |>
collect()
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2018.csv") |>
count(DestState) |>
collect()
toc()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2018.parquet") |>
count(DestState) |>
collect()
toc()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2018.csv") |> count()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2018.csv") |> nrow()
## CSV
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |>
count(DestState) |>
collect()
toc()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
count(DestState) |>
collect()
toc()
.172/5.27
5.27/.172
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |> nrows()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |> nrow()
243 / 2.21*1024
243 / (2.21*1024)
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet")
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv")
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet")
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
toc()
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
toc()
