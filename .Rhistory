left_join(dropoff) |>
count(pickup_borough, dropoff_borough) |>
arrange(desc(n)) |>
collect()
toc()
borough_counts
# Pivoting ----
library(tidyr)
# [A] Problem ----
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
head() |>
collect()
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
pivot_wider(-rate_code)
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
pivot_wider(-rate_code)
# [B] Solution ----
library(duckdb)
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance))
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
pivot_wider(names_from = 'rate_code', values_from = 'max_trip_dist') |>
# [B] Solution ----
library(duckdb)
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
pivot_wider(names_from = 'rate_code', values_from = 'max_trip_dist')
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
to_duckdb()
?to_duckdb
?to_arrow
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
to_duckdb() |>
pivot_wider(names_from = 'rate_code', values_from = 'max_trip_dist') |>
to_arrow() |>
collect()
nyc |>
filter(year > 2020) |>
select(year, contains('datetime'), total_amount)
# [A] Problem ----
nyc |>
filter(year > 2020) |>
select(year, contains('datetime'), total_amount) |>
group_by(year) |>
mutate(yearly_totals = sum(total_amount))
# [B] Solution ----
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
head() |>
to_arrow() |>
collect()
# [B] Solution ----
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
# head() |>
to_arrow() |>
collect()
tic()
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
to_arrow() |>
collect()
toc()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('datetime'), contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
?register_scalar_function
arrow::utf8()
arrow::float16()
arrow::float64()
## Solution ----
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
# head() |>
collect()
## User Defined Function
## Clean up strings ----
register_scalar_function(
# What should we call the function?
name = "clean_me",
# Define the function
# context must be the first argument
fun = function(context, var){
stringr::str_to_lower(var) |>
stringr::str_replace_all(" ", "_")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
tic()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
# head() |>
collect()
toc()
tic()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
# head() |>
collect() |>
dplyr::sample_n(n = 100)
# Using Custom Functions within arrow ----
## User Defined Function
## Clean up strings ----
register_scalar_function(
# What should we call the function?
name = "clean_me",
# Define the function
# context must be the first argument
fun = function(context, var){
stringr::str_to_lower(var) |>
stringr::str_replace_all(" ", "_")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
## Solution ----
tic()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
collect() |>
dplyr::sample_n(size = 100)
toc()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv")
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |> nrow()
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |>
count(DestState) |>
collect()
toc()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
count(DestState) |>
collect()
toc()
.169/4.777
4.777/.169
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
toc()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
toc()
4.917 / .164
years <- nyc |> distinct(year) |> collect() |> pull()
years
# connect to vendor partitioned data ----
nyc_vend <- open_dataset("data/nyc_part_vendor/")
tic()
nyc |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
toc()
tic()
nyc_vend |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
toc()
tic()
nyc |>
filter(vendor_name == "CMT") |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
toc()
tic()
nyc_vend |>
filter(vendor_name == "CMT") |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
toc()
tic()
nyc |>
filter(vendor_name == 'VTS') |>
group_by(year) |>
summarize(mean(tip_amount)) |>
collect()
toc()
tic()
nyc_vend |>
filter(vendor_name == 'VTS') |>
group_by(year) |>
summarize(mean(tip_amount)) |>
collect()
toc()
gc(1,1,1)
# setup ----
library(dplyr)
library(arrow)
library(tictoc) # useful to time commands
# open multi-file dataset
nyc <- open_dataset(here::here("data/nyc_part"))
nyc
object.size(nyc)
str(nyc)
schema(nyc)
nyc |> nrow()
# Data Manipulation ----
query <- nyc |>
filter(year == 2019) |>
select(fare_amount, passenger_count)
query
class(query)
schema(query)
tic()
query |>
collect() # execute the query!
toc()
nyc |>
filter(year == 2019) |>
select(fare_amount, passenger_count) |>
head() |>
collect()
tic()
nyc |>
filter(
str_ends(vendor_name, "S"),
year %in% c(2020, 2021),
month == 9) |>
collect()
toc()
nyc |>
select(
contains('pickup'),
ends_with('amount')
)
nyc |>
select(
where(is.character)
)
tic()
nyc |>
distinct(year, month) |>
arrange(year, -month) |>
collect()
toc()
tic()
nyc |>
distinct(vendor_name) |>
collect()
toc()
tic()
nyc |>
filter(year == 2019) |>
mutate(tip_percentage = tip_amount / fare_amount * 100) |>
select(fare_amount, tip_amount, tip_percentage) |>
collect()
toc()
## Using across ----
USD_TO_OMR <- 0.39
tic()
nyc |>
mutate(across(ends_with("amount"),
list('omr' = ~.x * USD_TO_OMR))) |>
select(contains('amount')) |>
head() |>
collect()
toc()
tic()
nyc |>
mutate(across(ends_with("amount"),
list('omr' = ~.x * USD_TO_OMR))) |>
select(contains('amount')) |>
head() |>
collect()
toc()
tic()
nyc |>
group_by(month) |>
summarize(
mean_fare = mean(fare_amount, na.rm = TRUE)
) |>
arrange(month) |>
collect()
toc()
tic()
nyc |>
filter(year %in% 2017:2021) |>
group_by(year) |>
summarize(
all_trips = n(),
shared_trips = sum(passenger_count > 1, na.rm = TRUE)
) |>
mutate(pct_shared = shared_trips / all_trips * 100) |>
collect()
toc()
tic()
nyc |>
group_by(year) |>
count(rate_code) |>
collect()
toc()
nyc_taxi_zones <-
read_csv_arrow(here::here("data/taxi_zone_lookup.csv")) |>
select(location_id = LocationID,
borough = Borough)
nyc_taxi_zones
nyc
nyc_taxi_zones_arrow <- arrow_table(
nyc_taxi_zones,
schema = schema(location_id = int64(), borough = utf8())
)
nyc_taxi_zones_arrow
pickup <- nyc_taxi_zones_arrow |>
select(pickup_location_id = location_id,
pickup_borough = borough)
dropoff <- nyc_taxi_zones_arrow |>
select(dropoff_location_id = location_id,
dropoff_borough = borough)
tic()
borough_counts <- nyc |>
left_join(pickup) |>
left_join(dropoff) |>
count(pickup_borough, dropoff_borough) |>
arrange(desc(n)) |>
collect()
toc()
borough_counts
# Pivoting ----
library(tidyr)
# [A] Problem ----
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
head() |>
collect()
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
pivot_wider(names_from = 'rate_code', values_from = 'max_trip_dist')
# [B] Solution ----
library(duckdb)
nyc |>
group_by(rate_code) |>
summarise(max_trip_dist = max(trip_distance)) |>
to_duckdb() |>
pivot_wider(names_from = 'rate_code', values_from = 'max_trip_dist') |>
to_arrow() |>
collect()
nyc |>
filter(year > 2020) |>
select(year, contains('datetime'), total_amount)
# [A] Problem ----
nyc |>
filter(year > 2020) |>
select(year, contains('datetime'), total_amount) |>
group_by(year) |>
mutate(yearly_totals = sum(total_amount))
tic()
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
to_arrow() |>
collect()
toc()
.Last.value
tic()
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
to_arrow() |>
collect()
toc()
nyc |>
to_duckdb() |>
filter(year %in% c(2018, 2020)) |>
select(year, contains('datetime'), contains('rate'), contains('amount')) |>
group_by(year) |>
mutate(yearly_total_amt = sum(total_amount)) |>
ungroup() |>
mutate(tip_pc = tip_amount / total_amount,
duration = dropoff_datetime - pickup_datetime) |>
show_query()
arrow::utf8()
arrow::float64()
## User Defined Function
## Clean up strings ----
register_scalar_function(
# What should we call the function?
name = "clean_me",
# Define the function
# context must be the first argument
fun = function(context, var){
stringr::str_to_lower(var) |>
stringr::str_replace_all(" ", "_")
},
# Schemas of input and output
in_type = schema(var = utf8()),
out_type = utf8(),
# Required to use in a dplyr pipeline
auto_convert = TRUE
)
tic()
nyc |>
filter(year == 2019, month == 1) |>
mutate(clean_rate_code = clean_me(rate_code)) |>
select(contains('rate_code')) |>
collect()
toc()
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |>
count(DestState) |>
collect()
toc()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
count(DestState) |>
collect()
toc() #30x faster!
tic()
open_csv_dataset(sources = "data/airlines/Combined_Flights_2021.csv") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
toc()
tic()
open_dataset(sources = "data/airlines/Combined_Flights_2021.parquet") |>
group_by(DestState) |>
summarise(mean(Distance)) |>
collect()
toc() #30x faster!
tic()
nyc |>
filter(vendor_name == "CMT") |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
toc()
tic()
nyc_vend |>
filter(vendor_name == "CMT") |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
# connect to vendor partitioned data ----
nyc_vend <- open_dataset("data/nyc_part_vendor/")
tic()
nyc_vend |>
filter(vendor_name == "CMT") |>
group_by(year, month, vendor_name) |>
summarise(max_trip_dist = max(trip_distance)) |>
collect()
toc() # 2x gain
nyc |>
filter(year > 2020) |>
select(year, contains('amount')) |>
group_by(year) |>
to_duckdb() |>
mutate(yearly_total_amt = sum(total_amount)) |>
collect()
